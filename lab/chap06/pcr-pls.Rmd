---
title: "实验：PCR 和 PLS 回归"
output: html_notebook
---

介绍两种降维 (dimension reduction) 方法：

- 主成分回归 (principal components regression, PCR)
- 偏最小二乘 (partial least squares, PLS)

```{r}
library(ISLR)
library(pls)
```

## 数据

棒球数据集，使用若干与棒球运动员上一年比赛成绩相关的变量来预测该运动员的薪水 (Salary)

```{r paged.print=FALSE}
head(Hitters)
```

```{r}
dim(Hitters)
```

```{r}
names(Hitters)
```

### 处理缺失值

```{r}
sum(is.na(Hitters))
```

删掉缺失值条目

```{r}
hitters <- na.omit(Hitters)
dim(hitters)
```

```{r}
sum(is.na(hitters))
```

### 数据集

构造数据集

```{r}
x <- model.matrix(Salary ~ ., hitters)[, -1]
y <- hitters$Salary
```

分割数据集

```{r}
set.seed(1)
train <- sample(1:nrow(x), nrow(x)/2)
test <- (-train)
y_test <- y[test]
```

## 主成分回归

主成分分析 (principal components analysis, PCA) 是一种可以从多个变量中得到低维变量的有效方法。

主成分回归 (principal components regression, PCR) 是指构造前 M 个主成分 Z_1，...，Z_M，以这些主成分作为预测变量，用最小二乘拟合线性回归模型。

pls 库中的 `pcr()` 函数实现主成分回归。

参数说明：

- `scale=TRUE`：变量标准化
- `validation="CV"`：使用十折交叉验证，计算每个主成分个数对应的交叉验证误差

```{r}
set.seed(1234)
pcr_fit <- pcr(
  Salary ~ .,
  data=hitters,
  scale=TRUE,
  validation="CV"
)
```

`summary()` 显示每个主成分个数对应的交叉得分，这里使用均方根误差 (RMSE)

`summary()` 也给出预测变量的被解释方差百分比 (percentage of variance explained) 和在不同数目成分下响应变量的被解释方差百分比。

```{r}
summary(pcr_fit)
```

使用 `validationplot()` 函数绘制 MSE 图像

```{r}
validationplot(
  pcr_fit,
  val.type="MSEP"
)
```

18 个成分时，RMSE 最小。但从 1 个成分开始，RMSE 相差不大，说明仅需要很少的变量就已经足够了。

### 交叉验证

在训练集上使用交叉验证

```{r}
set.seed(1234)
pcr_fit <- pcr(
  Salary ~ .,
  data=hitters,
  subset=train,
  scale=TRUE,
  validation="CV"
)
summary(pcr_fit)
```

```{r}
validationplot(
  pcr_fit,
  val.type="MSEP"
)
```

M = 5 时，交叉验证误差最小

计算测试集 MSE

```{r}
pcr_predict <- predict(
  pcr_fit,
  x[test,],
  ncomp=5
)
mean((pcr_predict - y_test)^2)
```

### 拟合

在整个数据集上拟合 PCR 模型

```{r}
pcr_fit <- pcr(
  y ~ x,
  scale=TRUE,
  ncomp=5
)
summary(pcr_fit)
```

## 偏最小二乘法

partial least squares, PLS

偏最小二乘法将原始变量的线性组合 Z_1，...，Z_M 作为新的变量集，用这 M 个新变量拟合最小二乘模型。

`plsr()` 函数

```{r}
set.seed(1)
pls_fit <- plsr(
  Salary ~ .,
  data=hitters,
  subset=train,
  scale=TRUE,
  validation="CV"
)
summary(pls_fit)
```

M = 1 时，交叉验证误差最小

计算测试集 MSE

```{r}
pls_predict <- predict(
  pls_fit,
  x[test,],
  ncomp=1
)
mean((pls_predict - y_test)^2)
```

### 拟合

在整个数据集上建立 PLS 模型

```{r}
pls_fit <- plsr(
  Salary ~ .,
  data=hitters,
  scale=TRUE,
  ncomp=1
)
summary(pls_fit)
```

## PCR 和 PLS 对比

| 方法 | 成分数量 | Salary 被解释方差比 |
|------|----------|-------------------|
| PCR | 5 | 44.90 |
| PLS | 1 | 43.05 |


PCR 目的是使预测变量可解释的方差最大化，而 PLS 旨在寻找可以同时解释预测变量和响应变量方差的方向。